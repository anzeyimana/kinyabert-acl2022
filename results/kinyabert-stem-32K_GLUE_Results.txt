Results for submission kinyabert-stem-32K-GLUE-0
Score: 61.7
Task	Metric	Score
The Corpus of Linguistic Acceptability	Matthew's Corr	0.0
The Stanford Sentiment Treebank	Accuracy	77.3
Microsoft Research Paraphrase Corpus	F1 / Accuracy	84.6/79.1
Semantic Textual Similarity Benchmark	Pearson-Spearman Corr	72.4/71.3
Quora Question Pairs	F1 / Accuracy	51.4/79.1
MultiNLI Matched	Accuracy	56.0
MultiNLI Mismatched	Accuracy	56.4
Question NLI	Accuracy	80.0
Recognizing Textual Entailment	Accuracy	58.0
Winograd NLI	Accuracy	65.1
Diagnostics Main	Matthew's Corr	9.2


Results for submission kinyabert-stem-32K-GLUE-1
Score: 62.0
Task	Metric	Score
The Corpus of Linguistic Acceptability	Matthew's Corr	0.0
The Stanford Sentiment Treebank	Accuracy	76.3
Microsoft Research Paraphrase Corpus	F1 / Accuracy	85.1/79.4
Semantic Textual Similarity Benchmark	Pearson-Spearman Corr	73.3/71.7
Quora Question Pairs	F1 / Accuracy	51.4/79.1
MultiNLI Matched	Accuracy	56.0
MultiNLI Mismatched	Accuracy	56.4
Question NLI	Accuracy	79.9
Recognizing Textual Entailment	Accuracy	60.7
Winograd NLI	Accuracy	65.1
Diagnostics Main	Matthew's Corr	9.2


Results for submission kinyabert-stem-32K-GLUE-2
Score: 62.1
Task	Metric	Score
The Corpus of Linguistic Acceptability	Matthew's Corr	0.0
The Stanford Sentiment Treebank	Accuracy	77.9
Microsoft Research Paraphrase Corpus	F1 / Accuracy	84.5/78.8
Semantic Textual Similarity Benchmark	Pearson-Spearman Corr	73.9/72.7
Quora Question Pairs	F1 / Accuracy	51.4/79.1
MultiNLI Matched	Accuracy	56.0
MultiNLI Mismatched	Accuracy	56.4
Question NLI	Accuracy	80.2
Recognizing Textual Entailment	Accuracy	59.4
Winograd NLI	Accuracy	65.1
Diagnostics Main	Matthew's Corr	9.2


Results for submission kinyabert-stem-32K-GLUE-3
Score: 58.7
Task	Metric	Score
The Corpus of Linguistic Acceptability	Matthew's Corr	0.0
The Stanford Sentiment Treebank	Accuracy	77.8
Microsoft Research Paraphrase Corpus	F1 / Accuracy	83.3/77.7
Semantic Textual Similarity Benchmark	Pearson-Spearman Corr	73.7/72.5
Quora Question Pairs	F1 / Accuracy	51.4/79.1
MultiNLI Matched	Accuracy	56.0
MultiNLI Mismatched	Accuracy	56.4
Question NLI	Accuracy	80.5
Recognizing Textual Entailment	Accuracy	60.4
Winograd NLI	Accuracy	34.9
Diagnostics Main	Matthew's Corr	9.2


Results for submission kinyabert-stem-32K-GLUE-4
Score: 61.8
Task	Metric	Score
The Corpus of Linguistic Acceptability	Matthew's Corr	0.0
The Stanford Sentiment Treebank	Accuracy	77.0
Microsoft Research Paraphrase Corpus	F1 / Accuracy	83.8/78.5
Semantic Textual Similarity Benchmark	Pearson-Spearman Corr	72.2/71.1
Quora Question Pairs	F1 / Accuracy	51.4/79.1
MultiNLI Matched	Accuracy	56.0
MultiNLI Mismatched	Accuracy	56.4
Question NLI	Accuracy	80.9
Recognizing Textual Entailment	Accuracy	58.7
Winograd NLI	Accuracy	65.1
Diagnostics Main	Matthew's Corr	9.2


Results for submission kinyabert-stem-32K-GLUE-5
Score: 61.9
Task	Metric	Score
The Corpus of Linguistic Acceptability	Matthew's Corr	0.0
The Stanford Sentiment Treebank	Accuracy	76.8
Microsoft Research Paraphrase Corpus	F1 / Accuracy	84.1/78.2
Semantic Textual Similarity Benchmark	Pearson-Spearman Corr	72.6/71.3
Quora Question Pairs	F1 / Accuracy	51.4/79.1
MultiNLI Matched	Accuracy	56.0
MultiNLI Mismatched	Accuracy	56.4
Question NLI	Accuracy	80.0
Recognizing Textual Entailment	Accuracy	60.7
Winograd NLI	Accuracy	65.1
Diagnostics Main	Matthew's Corr	9.2


Results for submission kinyabert-stem-32K-GLUE-6
Score: 62.0
Task	Metric	Score
The Corpus of Linguistic Acceptability	Matthew's Corr	0.0
The Stanford Sentiment Treebank	Accuracy	78.4
Microsoft Research Paraphrase Corpus	F1 / Accuracy	83.6/77.9
Semantic Textual Similarity Benchmark	Pearson-Spearman Corr	73.4/72.0
Quora Question Pairs	F1 / Accuracy	51.4/79.1
MultiNLI Matched	Accuracy	56.0
MultiNLI Mismatched	Accuracy	56.4
Question NLI	Accuracy	80.1
Recognizing Textual Entailment	Accuracy	59.6
Winograd NLI	Accuracy	65.1
Diagnostics Main	Matthew's Corr	9.2


Results for submission kinyabert-stem-32K-GLUE-7
Score: 60.7
Task	Metric	Score
The Corpus of Linguistic Acceptability	Matthew's Corr	0.0
The Stanford Sentiment Treebank	Accuracy	78.3
Microsoft Research Paraphrase Corpus	F1 / Accuracy	83.8/77.7
Semantic Textual Similarity Benchmark	Pearson-Spearman Corr	73.4/72.1
Quora Question Pairs	F1 / Accuracy	51.4/79.1
MultiNLI Matched	Accuracy	56.0
MultiNLI Mismatched	Accuracy	56.4
Question NLI	Accuracy	80.4
Recognizing Textual Entailment	Accuracy	60.4
Winograd NLI	Accuracy	52.7
Diagnostics Main	Matthew's Corr	9.2


Results for submission kinyabert-stem-32K-GLUE-8
Score: 60.8
Task	Metric	Score
The Corpus of Linguistic Acceptability	Matthew's Corr	0.0
The Stanford Sentiment Treebank	Accuracy	77.7
Microsoft Research Paraphrase Corpus	F1 / Accuracy	84.5/79.1
Semantic Textual Similarity Benchmark	Pearson-Spearman Corr	73.4/72.2
Quora Question Pairs	F1 / Accuracy	51.4/79.1
MultiNLI Matched	Accuracy	56.0
MultiNLI Mismatched	Accuracy	56.4
Question NLI	Accuracy	80.4
Recognizing Textual Entailment	Accuracy	60.0
Winograd NLI	Accuracy	52.7
Diagnostics Main	Matthew's Corr	9.2



Results for submission kinyabert-stem-32K-GLUE-9
Score: 62.3
Task	Metric	Score
The Corpus of Linguistic Acceptability	Matthew's Corr	0.0
The Stanford Sentiment Treebank	Accuracy	77.6
Microsoft Research Paraphrase Corpus	F1 / Accuracy	85.0/79.5
Semantic Textual Similarity Benchmark	Pearson-Spearman Corr	74.2/73.0
Quora Question Pairs	F1 / Accuracy	51.4/79.1
MultiNLI Matched	Accuracy	56.0
MultiNLI Mismatched	Accuracy	56.4
Question NLI	Accuracy	80.4
Recognizing Textual Entailment	Accuracy	60.4
Winograd NLI	Accuracy	65.1
Diagnostics Main	Matthew's Corr	9.2
