{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating ./kinlpmorpholib.c\n",
      "(already up-to-date)\n",
      "the current directory is '/home/user/projects/user/kinyabert/modeling/kinyabert'\n",
      "running build_ext\n",
      "building 'kinlpmorpholib' extension\n",
      "gcc -pthread -B /home/user/anaconda3/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -I/home/user/anaconda3/include/python3.8 -c kinlpmorpholib.c -o ./kinlpmorpholib.o -fopenmp -D use_openmp -O3 -march=native -ffast-math\n",
      "gcc -pthread -shared -B /home/user/anaconda3/compiler_compat -L/home/user/anaconda3/lib -Wl,-rpath=/home/user/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ ./kinlpmorpholib.o -lkinlp -o ./kinlpmorpholib.cpython-38-x86_64-linux-gnu.so -fopenmp\n",
      "\n",
      "2021-07-26 13:52:18\tSetting up KINLP dictionary...\n",
      "\n",
      "2021-07-26 13:52:19\tKINLP dictionary size: 2294464\n",
      "\n",
      "2021-07-26 13:52:19\tParsing match/req rules...\n",
      "total_pref_require_global_ids: 408\n",
      "Initiated all POS classes: 149\n",
      "\n",
      "2021-07-26 13:52:19\tReading known lexicon...\n",
      "\tSpecial words: 401\n",
      "\tVerbs lemma: 8154\n",
      "\tCommon verbs lemma: 1918\n",
      "\tLemmatized verbs: 4464\n",
      "\tNouns lemma: 17044\n",
      "\tCommon nouns lemma: 4434\n",
      "\n",
      "2021-07-26 13:52:19\tReading collected stem features...\n",
      "\tCollected verb stem features: 3058\n",
      "\n",
      "2021-07-26 13:52:19\tInitializing word vectors...\n",
      "99.50%\r\n",
      "2021-07-26 13:53:38\tLoaded 1376872 word vectors.\n",
      "\n",
      "2021-07-26 13:53:38\tInitializing common stem inflections...\n",
      "\n",
      "2021-07-26 13:53:38\tStem inflections gotten: 3779/3465\n",
      "\n",
      "2021-07-26 13:53:39\tUn-segmentable words: 397665\n",
      "Read: 1331449 V\n",
      "Read: 345368 N\n",
      "Read: 627 QA\n",
      "Read: 552 PO\n",
      "Read: 554 DE\n",
      "Read: 116 NU\n",
      "Read: 160 OT\n",
      "\n",
      "2021-07-26 13:53:50\tConfidence stats: \n",
      "V/mean: 905926.6875\n",
      "V/sdev: 240333680.0000\n",
      "\n",
      "N/mean: 0.0314\n",
      "N/sdev: 0.1658\n",
      "\n",
      "QA/mean: 1.0000\n",
      "QA/sdev: 0.0000\n",
      "\n",
      "PO/mean: 1.0000\n",
      "PO/sdev: 0.0000\n",
      "\n",
      "DE/mean: 1.0000\n",
      "DE/sdev: 0.0000\n",
      "\n",
      "NU/mean: 1.0000\n",
      "NU/sdev: 0.0000\n",
      "\n",
      "OT/mean: 1.0000\n",
      "OT/sdev: 0.0000\n",
      "\n",
      "\n",
      "2021-07-26 13:53:50\tInitialization complete.\n",
      "2021-07-26 13:53:50 KINLP Ready!\n",
      "Using device:  cpu\n",
      "Vocab ready!\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "from __future__ import print_function, division\n",
    "import gc\n",
    "import sys\n",
    "import torch\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def time_now():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "from kinlpmorpho import build_kinlp_morpho_lib\n",
    "\n",
    "build_kinlp_morpho_lib()\n",
    "\n",
    "from kinlpmorpholib import ffi, lib\n",
    "\n",
    "from wurlitzer import sys_pipes\n",
    "\n",
    "with sys_pipes():\n",
    "    conf = \"/mnt/NVM/KINLP/data/kb_config_kinlp.conf\"\n",
    "    lib.start_kinlp_lib(conf.encode('utf-8'))\n",
    "\n",
    "print(time_now(), 'KINLP Ready!', flush=True)\n",
    "\n",
    "# %%\n",
    "\n",
    "import importlib\n",
    "import morpho_data_loaders\n",
    "import morpho_model\n",
    "\n",
    "importlib.reload(morpho_data_loaders)\n",
    "importlib.reload(morpho_model)\n",
    "\n",
    "import youtokentome as yttm\n",
    "from morpho_data_loaders import KBVocab, AffixSetVocab, morpho_model_seq_predict\n",
    "from morpho_model import kinyabert_base\n",
    "\n",
    "from test_inference_data_loaders import inf_gather_replicated_itemized_data\n",
    "\n",
    "home_path = \"/mnt/NVM/KINLP/\"\n",
    "USE_GPU = False\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using device: ', device)\n",
    "\n",
    "BPE_model_path = (home_path + \"data/BPE-30k.mdl\")\n",
    "bpe_encoder = yttm.BPE(model=BPE_model_path)\n",
    "\n",
    "kb_vocab = KBVocab()\n",
    "kbvocab_state_dict_file_path = (home_path + \"data/kb_vocab_state_dict_2021-02-07.pt\")\n",
    "kb_vocab.load_state_dict(torch.load(kbvocab_state_dict_file_path))\n",
    "\n",
    "affix_set_vocab = AffixSetVocab(reduced_affix_dict_file=home_path+\"data/reduced_affix_dict_10000.csv\",\n",
    "                                    reduced_affix_dict_map_file=home_path+\"data/reduced_affix_dict_map_10000.csv\")\n",
    "print('Vocab ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from morpho_model import KinyaBERT\n",
    "\n",
    "def morpho_test_mlm_inference(args, input_line, kb_vocab : KBVocab, affix_set_vocab : AffixSetVocab, bpe_encoder, kinya_bert_model : KinyaBERT, morpho_rel_pos_dict, morpho_rel_pos_dmax, mask_ids, proposed_stem_ids=None):\n",
    "    stem_acc = 0.0\n",
    "    afset_acc = 0.0\n",
    "    affix_acc = 0.0\n",
    "\n",
    "    stem_sum_acc = 0.0\n",
    "    afset_sum_acc = 0.0\n",
    "    affix_sum_acc = 0.0\n",
    "\n",
    "    itemized_data, itemized_parsed_tokens = inf_gather_replicated_itemized_data(args, input_line, 512, kb_vocab, affix_set_vocab, bpe_encoder, morpho_rel_pos_dict, morpho_rel_pos_dmax, mask_ids)\n",
    "\n",
    "    for myidx, data_item in enumerate(itemized_data):\n",
    "        seq_parsed_tokens = itemized_parsed_tokens[myidx]\n",
    "        (max_seq_len,\n",
    "         seq_rel_pos_arr,\n",
    "         seq_pos_tags,\n",
    "         seq_stems,\n",
    "         seq_afsets,\n",
    "         seq_affixes,\n",
    "         seq_tokens_lengths,\n",
    "         seq_predicted_stems,\n",
    "         seq_predicted_afsets,\n",
    "         seq_predicted_affixes,\n",
    "         seq_predicted_tokens_idx,\n",
    "         seq_predicted_tokens_affixes_idx,\n",
    "         seq_predicted_tokens_affixes_lengths) = data_item\n",
    "\n",
    "        (stem_predictions, stem_predictions_prob, afset_predictions, afset_predictions_prob, affix_predictions) = morpho_model_seq_predict(args, data_item,\n",
    "                                                                                                kinya_bert_model,\n",
    "                                                                                                device, 10, proposed_stem_ids=proposed_stem_ids)\n",
    "\n",
    "        np.set_printoptions(precision=3, linewidth=np.inf)\n",
    "        print('\\nstem_predictions:', stem_predictions.detach().numpy().tolist())\n",
    "        print('\\nseq_predicted_stems:', seq_predicted_stems)\n",
    "        print('\\nafset_predictions:', afset_predictions)\n",
    "        print('\\nstem_predictions_prob:', stem_predictions_prob.detach().numpy())\n",
    "        print('\\nseq_predicted_tokens_affixes_lengths:', seq_predicted_tokens_affixes_lengths)\n",
    "        print('\\nseq_predicted_tokens_affixes_idx:', seq_predicted_tokens_affixes_idx)\n",
    "        print('\\naffix_predictions:', affix_predictions)\n",
    "        print('\\nseq_predicted_affixes:', seq_predicted_affixes, '\\n')\n",
    "\n",
    "        stems_count = 0\n",
    "        affixes_count = 0\n",
    "        affixes_total = 0\n",
    "        afx = 0\n",
    "        ptk = 0\n",
    "        next_ptk_idx = 0\n",
    "        ptoken = seq_parsed_tokens[0]\n",
    "        for i in range(len(seq_tokens_lengths)):\n",
    "            # 1. Print Token\n",
    "            # Keep the same token until all stem_idx are handled\n",
    "            if (next_ptk_idx == i):\n",
    "                ptoken = seq_parsed_tokens[ptk]\n",
    "                next_ptk_idx = i + len(ptoken.stem_idx)\n",
    "                ptk += 1\n",
    "            print('\\n{} @ --> {} {} {} ==> {}'.format(ptoken.surface_form,\n",
    "                                                      kb_vocab.pos_tag_vocab_idx[ptoken.pos_tag_idx],\n",
    "                                                      [kb_vocab.affix_vocab_idx[k] for k in ptoken.affixes_idx],\n",
    "                                                      [kb_vocab._stem_vocab_idx[k] for k in ptoken.stem_idx],\n",
    "                                                      [kb_vocab.reduced_stem_vocab_idx[\n",
    "                                                           kb_vocab.mapped_stem_vocab_idx[k]] for k in\n",
    "                                                       ptoken.stem_idx]))\n",
    "\n",
    "            # 1.5 Print input stem,pos & affixes\n",
    "            print('Input:', '{}/{}'.format(kb_vocab.pos_tag_vocab_idx[seq_pos_tags[i]],\n",
    "                                           kb_vocab.reduced_stem_vocab_idx[seq_stems[i]]),\n",
    "                  ['{}'.format(kb_vocab.affix_vocab_idx[a]) for a in\n",
    "                   seq_affixes[afx:(afx + seq_tokens_lengths[i])]])\n",
    "            afx += seq_tokens_lengths[i]\n",
    "\n",
    "            # 2. Stem Prediction\n",
    "            if i in seq_predicted_tokens_idx:\n",
    "                pstem = kb_vocab.reduced_stem_vocab_idx[seq_predicted_stems[stems_count]]\n",
    "                _pstem = kb_vocab.reduced_stem_vocab_idx[stem_predictions[stems_count].item()]\n",
    "                _pstem_prob = stem_predictions_prob[stems_count].item()\n",
    "                print('{} [STEM]>>>> Gold: {} --> Pred: {} @ {:.3}'.format((pstem == _pstem), pstem, _pstem,\n",
    "                                                                           _pstem_prob))\n",
    "                stem_sum_acc += 1\n",
    "                if (pstem == _pstem):\n",
    "                    stem_acc += 1\n",
    "\n",
    "                if seq_predicted_afsets is not None:\n",
    "                    pafset = affix_set_vocab.affix_set_idx_to_txt(seq_predicted_afsets[stems_count], kb_vocab)\n",
    "                    _pafset = affix_set_vocab.affix_set_idx_to_txt(afset_predictions[stems_count].item(), kb_vocab)\n",
    "                    _pafset_prob = afset_predictions_prob[stems_count].item()\n",
    "                    print('{} [AFSET]>>>> Gold: {} --> Pred: {} @ {:.3}'.format((pafset == _pafset), pafset, _pafset,\n",
    "                                                                           _pafset_prob))\n",
    "                    afset_sum_acc += 1\n",
    "                    if (pafset == _pafset):\n",
    "                        afset_acc += 1\n",
    "\n",
    "                # 3. Affix Prediction\n",
    "                if stems_count in seq_predicted_tokens_affixes_idx:\n",
    "                    flen = seq_predicted_tokens_affixes_lengths[affixes_count]\n",
    "                    paffixes = set([kb_vocab.affix_vocab_idx[a] for a in\n",
    "                                    seq_predicted_affixes[affixes_total:(affixes_total + flen)]])\n",
    "                    _paffixes = set([kb_vocab.affix_vocab_idx[a] for a in affix_predictions[affixes_count]])\n",
    "                    incr = float(len(paffixes.intersection(_paffixes))) / float(len(paffixes))\n",
    "                    print('{} @ {:.2f} [AFFIX]>>> Gold: {} --> Pred: {}'.format((paffixes == _paffixes), incr,\n",
    "                                                                                paffixes, _paffixes))\n",
    "                    affixes_count += 1\n",
    "                    affixes_total += flen\n",
    "                    affix_sum_acc += 1\n",
    "                    affix_acc += incr\n",
    "                    # if (paffixes == _paffixes):\n",
    "                    #     affix_acc += 1\n",
    "                stems_count += 1\n",
    "        print(\n",
    "            '\\n-------------------------------------------------------------------- NEW SEQUENCE ---------------------------------------------------------------------\\n')\n",
    "    print(input_line, '\\n', 'ACCURACY%:>> STEM: {:.2f}%({:.0f}/{:.0f}) \\t AFSET: {:.2f}%({:.0f}/{:.0f}) \\t AFFIX: {:.2f}%({:.2f}/{:.2f})'.format(\n",
    "        (100.0 * stem_acc / (stem_sum_acc + 1e-7)), stem_acc, stem_sum_acc,\n",
    "        (100.0 * afset_acc / (afset_sum_acc + 1e-7)), afset_acc, afset_sum_acc,\n",
    "        100.0 * affix_acc / (affix_sum_acc + 1e-7), affix_acc, affix_sum_acc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call arguments:\n",
      " Namespace(accumulation_steps=128, batch_size=20, cls_dev_input0=None, cls_dev_input1=None, cls_dev_label=None, cls_labels='0,1', cls_test_input0=None, cls_test_input1=None, cls_test_label=None, cls_train_input0=None, cls_train_input1=None, cls_train_label=None, devbest_cls_model_save_file_path=None, devbest_cls_output_file=None, embed_dim=768, final_cls_model_save_file_path=None, final_cls_output_file=None, gpus=1, home_path='/home/user/KINLP/', inference_iters=1, inference_runs=1, layernorm_epsilon=1e-06, max_input_lines=999999, max_seq_len=512, morpho_dim=128, morpho_tr_dim_feedforward=512, morpho_tr_dropout=0.1, morpho_tr_nhead=4, morpho_tr_nlayers=4, num_epochs=20, num_inference_iters=1, num_inference_runs=1, num_iters=200000, num_pos_m_embeddings=3, num_stem_m_embeddings=1, number_of_load_batches=384, peak_lr=0.0004, pooler_dropout=0.1, pos=3, pretrained_model_file=None, pretrained_roberta_checkpoint_file='checkpoint_best.pt', pretrained_roberta_model_dir='/home/user/KINLP/data/', regression_scale_factor=1.0, regression_target=False, seq_tr_dim_feedforward=3072, seq_tr_dropout=0.1, seq_tr_nhead=12, seq_tr_nlayers=12, stem=1, stem_dim=256, use_affix_bow=False, use_affix_bow_m_embedding=False, use_pos_aware_rel=True, use_pos_aware_rel_pos_bias=True, use_tupe_rel=False, use_tupe_rel_pos_bias=False, warmup_iter=2000, warmup_ratio=0.06, wd=0.01, world_size=1, xlmr=False)\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from morpho_common import setup_common_args\n",
    "args = setup_common_args(\"-g 1 -p 3 -s 1 --use-pos-aware-rel=1 --use-tupe-rel=0\".split(' '))\n",
    "\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '88599'\n",
    "dist.init_process_group(backend='gloo', init_method='env://', world_size=1, rank=0)\n",
    "\n",
    "morpho_rel_pos_dict = None\n",
    "morpho_rel_pos_dmax = 5\n",
    "if args.use_pos_aware_rel_pos_bias:\n",
    "    morpho_rel_pos_dict_file_path = (home_path+\"data/morpho_rel_pos_dict_2021-03-24.pt\")\n",
    "    saved_pos_rel_dict = torch.load(morpho_rel_pos_dict_file_path)\n",
    "    morpho_rel_pos_dict = saved_pos_rel_dict['morpho_rel_pos_dict']\n",
    "    morpho_rel_pos_dmax = saved_pos_rel_dict['morpho_rel_pos_dmax']\n",
    "\n",
    "kb_model = kinyabert_base(kb_vocab, affix_set_vocab, morpho_rel_pos_dict,\n",
    "                       device, args, saved_model_file=None)\n",
    "ddp_model = DDP(kb_model)\n",
    "\n",
    "file = \"/mnt/NVM/KinyaBERT_Checkpoints/kb_attentive/backup_07_24_morpho_attentive_model_base_2021-04-19.pt\"\n",
    "\n",
    "kb_state_dict = torch.load(file,map_location=device)\n",
    "ddp_model.load_state_dict(kb_state_dict['model_state_dict'])\n",
    "kb_model = ddp_model.module\n",
    "kb_model.eval()\n",
    "\n",
    "print('OK')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stem_predictions: [575]\n",
      "\n",
      "seq_predicted_stems: [183]\n",
      "\n",
      "stem_predictions_prob: [0.225]\n",
      "\n",
      "seq_predicted_tokens_affixes_lengths: [3]\n",
      "\n",
      "seq_predicted_tokens_affixes_idx: [0]\n",
      "\n",
      "affix_predictions: [[26, 5, 13, 66, 36, 9, 35, 12, 171, 20]]\n",
      "\n",
      "seq_predicted_affixes: [5, 66, 26] \n",
      "\n",
      "\n",
      "<CLS> @ --> <CLS> ['<EOT>'] ['<CLS>'] ==> ['<CLS>']\n",
      "Input: <CLS>/<CLS> []\n",
      "\n",
      "umuyobozi @ --> N#012 ['N:0:u', 'N:1:mu'] ['N:yobozi'] ==> ['N:yobozi']\n",
      "Input: N#012/N:yobozi ['N:0:u', 'N:1:mu']\n",
      "\n",
      "ushinzwe @ --> V#010 ['V:2:u', 'V:16:y', 'V:17:w', 'V:18:ye'] ['V:shing'] ==> ['V:shing']\n",
      "Input: V#010/V:shing ['V:2:u', 'V:16:y', 'V:17:w', 'V:18:ye']\n",
      "\n",
      "ishami @ --> N#012 ['N:0:i'] ['N:shami'] ==> ['N:shami']\n",
      "Input: N#012/N:shami ['N:0:i']\n",
      "\n",
      "rya @ --> PO#022 ['PO:1:ri'] ['PO:a'] ==> ['PO:a']\n",
      "Input: PO#022/PO:a ['PO:1:ri']\n",
      "\n",
      "imisoro @ --> N#012 ['N:0:i', 'N:1:mi'] ['N:soro'] ==> ['N:soro']\n",
      "Input: N#012/N:soro ['N:0:i', 'N:1:mi']\n",
      "\n",
      "ya @ --> PO#022 ['PO:1:i'] ['PO:a'] ==> ['PO:a']\n",
      "Input: PO#022/PO:a ['PO:1:i']\n",
      "\n",
      "inzego @ --> N#012 ['N:0:i', 'N:1:n'] ['N:ego'] ==> ['N:ego']\n",
      "Input: N#012/N:ego ['N:0:i', 'N:1:n']\n",
      "\n",
      "za @ --> PO#022 ['PO:1:zi'] ['PO:a'] ==> ['PO:a']\n",
      "Input: PO#022/PO:a ['PO:1:zi']\n",
      "\n",
      "ibanze @ --> N#012 ['N:0:i'] ['N:banze'] ==> ['N:banze']\n",
      "Input: N#012/N:banze ['N:0:i']\n",
      "\n",
      "muri @ --> PR#060 [] ['PR:▁muri'] ==> ['PR:▁muri']\n",
      "Input: PR#060/PR:▁muri []\n",
      "\n",
      "rra @ --> NP#035 [] ['NP:▁rra'] ==> ['NP:▁rra']\n",
      "Input: NP#035/NP:▁rra []\n",
      "\n",
      "avuga @ --> V#010 ['V:2:a', 'V:18:a'] ['V:vug'] ==> ['V:vug']\n",
      "Input: V#010/V:vug ['V:2:a', 'V:18:a']\n",
      "\n",
      "ko @ --> CJ#071 [] ['CJ:▁ko'] ==> ['CJ:▁ko']\n",
      "Input: CJ#071/CJ:▁ko []\n",
      "\n",
      "ibyo @ --> DE#021 ['DE:1:i', 'DE:2:bi'] ['DE:o'] ==> ['DE:o']\n",
      "Input: DE#021/DE:o ['DE:1:i', 'DE:2:bi']\n",
      "\n",
      "bibazo @ --> N#011 ['N:1:bi'] ['N:bazo'] ==> ['N:bazo']\n",
      "Input: N#011/N:bazo ['N:1:bi']\n",
      "\n",
      "byavuzwe @ --> V#009 ['V:2:bi', 'V:4:a', 'V:17:w', 'V:18:ye'] ['V:vug'] ==> ['V:vug']\n",
      "Input: V#009/V:vug ['V:2:bi', 'V:4:a', 'V:17:w', 'V:18:ye']\n",
      "\n",
      "ariko @ --> VC#038 [] ['VC:▁ariko'] ==> ['VC:▁ariko']\n",
      "Input: VC#038/VC:▁ariko []\n",
      "\n",
      "nta @ --> CP#078 [] ['CP:▁nta'] ==> ['CP:▁nta']\n",
      "Input: CP#078/CP:▁nta []\n",
      "\n",
      "mwanzuro @ --> N#011 ['N:1:mu'] ['N:anzuro'] ==> ['N:anzuro']\n",
      "Input: N#011/N:anzuro ['N:1:mu']\n",
      "\n",
      "wigeze @ --> V#010 ['V:2:u', 'V:9:ii', 'V:18:e'] ['V:gez'] ==> ['V:gez']\n",
      "Input: <MSK>/<MSK> []\n",
      "False [STEM]>>>> Gold: V:gez --> Pred: V:iger @ 0.225\n",
      "False @ 1.00 [AFFIX]>>> Gold: {'V:2:u', 'V:18:e', 'V:9:ii'} --> Pred: {'V:2:u', 'V:18:ye', 'V:18:a', 'V:16:y', 'V:17:w', 'V:8:ri', 'V:4:a', 'V:9:ii', 'V:18:e', 'V:2:bi'}\n",
      "\n",
      "ubagezwaho @ --> V#010 ['V:2:u', 'V:8:ba', 'V:17:w', 'V:18:a', 'V:19:ho'] ['V:gez'] ==> ['V:gez']\n",
      "Input: V#010/V:gez ['V:2:u', 'V:8:ba', 'V:17:w', 'V:18:a', 'V:19:ho']\n",
      "\n",
      "wo @ --> PO#022 ['PO:1:u'] ['PO:o'] ==> ['PO:o']\n",
      "Input: PO#022/PO:o ['PO:1:u']\n",
      "\n",
      "kutabara @ --> V#000 ['V:2:ku', 'V:3:ta', 'V:18:a'] ['V:bar'] ==> ['V:bar']\n",
      "Input: V#000/V:bar ['V:2:ku', 'V:3:ta', 'V:18:a']\n",
      "\n",
      "imisoro @ --> N#012 ['N:0:i', 'N:1:mi'] ['N:soro'] ==> ['N:soro']\n",
      "Input: N#012/N:soro ['N:0:i', 'N:1:mi']\n",
      "\n",
      "ku @ --> PR#057 [] ['PR:▁ku'] ==> ['PR:▁ku']\n",
      "Input: PR#057/PR:▁ku []\n",
      "\n",
      "bikorwa @ --> V#010 ['V:2:bi', 'V:17:w', 'V:18:a'] ['V:kor'] ==> ['V:kor']\n",
      "Input: V#010/V:kor ['V:2:bi', 'V:17:w', 'V:18:a']\n",
      "\n",
      "bya @ --> PO#022 ['PO:1:bi'] ['PO:a'] ==> ['PO:a']\n",
      "Input: PO#022/PO:a ['PO:1:bi']\n",
      "\n",
      "abihayimana @ --> V#010 ['V:2:a', 'V:6:bi', 'V:7:ha', 'V:8:yi', 'V:13:an', 'V:18:a'] ['V:im'] ==> ['V:im']\n",
      "Input: V#010/V:im ['V:2:a', 'V:6:bi', 'V:7:ha', 'V:8:yi', 'V:13:an', 'V:18:a']\n",
      "\n",
      ". @ --> PT#086 [] ['PT:▁.'] ==> ['PT:▁.']\n",
      "Input: PT#086/PT:▁. []\n",
      "\n",
      "-------------------------------------------------------------------- NEW SEQUENCE ---------------------------------------------------------------------\n",
      "\n",
      "Umuyobozi ushinzwe ishami ry’imisoro y’inzego z’ibanze muri RRA avuga ko ibyo bibazo byavuzwe ariko nta mwanzuro wigeze ubagezwaho wo kutabara imisoro ku bikorwa by’Abihayimana. \n",
      " ACCURACY%:>> STEM: 0.00%(0/1) \t AFFIX: 100.00%(1.00/1.00)\n"
     ]
    }
   ],
   "source": [
    "input_line = \"Umuyobozi ushinzwe ishami ry’imisoro y’inzego z’ibanze muri RRA avuga ko ibyo bibazo byavuzwe ariko nta mwanzuro wigeze ubagezwaho wo kutabara imisoro ku bikorwa by’Abihayimana.\"\n",
    "mask_ids = [20]\n",
    "proposed_stems = [\"V:ger\",\"V:iger\"]\n",
    "proposed_stem_ids = [kb_vocab.reduced_stem_vocab[s] for s in proposed_stems]\n",
    "morpho_test_mlm_inference(args, input_line, kb_vocab, affix_set_vocab, bpe_encoder, kb_model, morpho_rel_pos_dict, morpho_rel_pos_dmax, mask_ids, proposed_stem_ids=proposed_stem_ids)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}